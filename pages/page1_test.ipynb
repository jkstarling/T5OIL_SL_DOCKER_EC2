{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'T5_funcs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# from dotenv import load_dotenv\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# load_dotenv('.env')  # take environment variables from .env.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mT5_funcs\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mT5f\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtake5_functions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mt5f\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'T5_funcs'"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pymysql\n",
    "import os\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv('.env')  # take environment variables from .env.\n",
    "import datetime\n",
    "import T5_funcs as T5f\n",
    "import take5_functions as t5f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from dash import Dash, html\n",
    "import dash_ag_grid as dag \n",
    "from st_aggrid import AgGrid\n",
    "from helper import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import hmac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:27: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:27: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\beets\\AppData\\Local\\Temp\\ipykernel_7996\\3184939665.py:27: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  try: controlmap = pd.read_excel(cwdir + '\\control_map.xlsx', index_col=None)\n",
      "C:\\Users\\beets\\AppData\\Local\\Temp\\ipykernel_7996\\3184939665.py:27: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  try: controlmap = pd.read_excel(cwdir + '\\control_map.xlsx', index_col=None)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'T5_funcs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# from dotenv import load_dotenv\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# load_dotenv('.env')  # take environment variables from .env.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mT5_funcs\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mT5f\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtake5_functions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mt5f\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'T5_funcs'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "\n",
    "# Get the directory of the current script\n",
    "cwdir = os.path.dirname(__file__)\n",
    "cwdirup1 = os.path.dirname(cwdir)\n",
    "# st.write(cwdir)\n",
    "try: controlmap = pd.read_excel(cwdir + '\\control_map.xlsx', index_col=None)\n",
    "except: controlmap = pd.read_excel(cwdir + '/control_map.xlsx', index_col=None)\n",
    "\n",
    "try: extra = pd.read_csv(cwdirup1 + '\\\\t5_extra_data.csv', index_col=None)\n",
    "except: extra = pd.read_csv(cwdirup1 + '/t5_extra_data.csv', index_col=None)\n",
    "\n",
    "try: workdays = pd.read_csv(cwdirup1 + '\\\\t5_workdays.csv', index_col=None)\n",
    "except: workdays = pd.read_csv(cwdirup1 + '/t5_workdays.csv', index_col=None)\n",
    "\n",
    "locations = [(1402,'1402 - Ten Mile'), \n",
    "            (1403, '1403 - Caldwell'), \n",
    "            (1404, '1404 - Glenwood'), \n",
    "            (1405, '1405 - Ontario'), \n",
    "            (1407, '1407 - Pasco'), \n",
    "            (1881, '1881 - Lacey')]\n",
    "loc_df = pd.DataFrame(locations, columns=['Location', 'location'])\n",
    "loc_df['Location'] = loc_df['Location'].astype('int64')\n",
    "\n",
    "extra = extra.merge(loc_df, how='left', on='Location')\n",
    "\n",
    "extra['Date'] = pd.to_datetime(extra.Date, format='%y-%b', errors='coerce')\n",
    "workdays['date'] = pd.to_datetime(workdays.date, format='%b-%y', errors='coerce')#.dt.strftime('%b %y')\n",
    "# st.write(workdays)\n",
    "\n",
    "# get secrets from st.secrets\n",
    "host = st.secrets[\"host\"]#os.getenv('host') \n",
    "user = st.secrets[\"user\"]#os.getenv('user')\n",
    "port = st.secrets[\"port\"]#os.getenv('port')\n",
    "password = st.secrets[\"password\"]#os.getenv('password')\n",
    "databasename = st.secrets[\"databasename\"]#os.getenv('databasename')\n",
    "\n",
    "#### read in data\n",
    "connection = T5f.make_connection(host, user, port, password, databasename)\n",
    "df = T5f.read_in_SQL(connection)\n",
    "\n",
    "df = df.loc[(df.location != 'Admin') & (df.location != 'Not Specified') & (df.location != 'Saranac'),:]\n",
    "\n",
    "\n",
    "#### get data within dates. Baseline is 13 months.\n",
    "maxdate = max(df.monthdt)\n",
    "mindate = maxdate - pd.DateOffset(months=12)\n",
    "\n",
    "with st.sidebar:\n",
    "    options = st.multiselect('Select the Take 5 Oil Locations you want to perform analsysis on:', \n",
    "                            df.location.unique(), df.location.unique())\n",
    "    startdate = st.date_input(\"Please enter a starting date (must pick 1st of month):\", mindate.date())\n",
    "    enddate = st.date_input(\"Please enter a ending date:\", maxdate.date())\n",
    "startdate = pd.to_datetime(startdate)\n",
    "enddate = pd.to_datetime(enddate)\n",
    "\n",
    "# trim data based on selected/standard dates\n",
    "df_new = df[(df['monthdt'] >= startdate) & (df['monthdt'] <= enddate) & (df.location.isin(options))]\n",
    "\n",
    "ext_melt = pd.melt(extra, \n",
    "                     id_vars=['Location', 'location', 'Date'], \n",
    "                     var_name='metric', \n",
    "                     value_name='value').dropna(subset=['value'])\n",
    "ext_melt = ext_melt[(ext_melt.location.isin(options))]\n",
    "\n",
    "ext_avg = ext_melt[(ext_melt['Date'] >= startdate) & \n",
    "                   (ext_melt['Date'] <= enddate) & \n",
    "                   (ext_melt.metric.isin(['BayTimes','Pmix_perc','Big5_perc']))]\n",
    "ext_sum = ext_melt[(ext_melt['Date'] >= startdate) & \n",
    "                   (ext_melt['Date'] <= enddate) & \n",
    "                   (ext_melt.metric.isin(['CarsServ','EmpHours']))]\n",
    "\n",
    "workdays = workdays[(workdays['date'] >= startdate) & \n",
    "                    (workdays['date'] <= enddate)]\n",
    "\n",
    "\n",
    "#### create monthly pivot table and display. \n",
    "pivot_df = T5f.create_T5_pivot_table(result_df=df_new, ext_avg=ext_avg, \n",
    "                                     ext_sum=ext_sum, controlmap=controlmap,\n",
    "                                     workdays=workdays)\n",
    "\n",
    "st.dataframe(pivot_df)\n",
    "\n",
    "\n",
    "# st.write('Here is the dataframe with AG GRID')\n",
    "# AgGrid(pivot_df, height=800)\n",
    "\n",
    "\n",
    "###### crate dataframes for figures\n",
    "#### create revenue by location dataframe\n",
    "ind = (df_new.Account_Num >4000) & (df_new.Account_Num <4999)\n",
    "df_rev = df_new[ind].groupby(['location','monthdt'])['value'].sum()#.reset_index()\n",
    "tot_rev_by_date = df_rev.reset_index().groupby('monthdt')['value'].sum().reset_index()\n",
    "\n",
    "\n",
    "#### create # of cars serviced dataframe\n",
    "ext_cars_by_loc = ext_melt[ext_melt.metric == 'CarsServ']\n",
    "tot_cars_by_date = ext_cars_by_loc.groupby('Date')['value'].sum().reset_index()\n",
    "\n",
    "#### create gross profit dataframe\n",
    "ind = (df_new.Account_Num >5000) & (df_new.Account_Num <5998)\n",
    "df_cogs = df_new[ind].groupby(['location','monthdt'])['value'].sum()#.reset_index()\n",
    "df_gross = df_rev - df_cogs\n",
    "tot_gross_by_date = df_gross.reset_index().groupby('monthdt')['value'].sum().reset_index()\n",
    "# st.write(df_gross)\n",
    "\n",
    "#### create 4-wall EBITDA dataframe\n",
    "ind = (df_new.Account_Num >6000) & (df_new.Account_Num <7999)\n",
    "df_4wexpenses = df_new[ind].groupby(['location','monthdt'])['value'].sum()#.reset_index()\n",
    "df_4webitda = df_gross - df_4wexpenses\n",
    "tot_ebitda_by_date = df_4webitda.reset_index().groupby('monthdt')['value'].sum().reset_index()\n",
    "\n",
    "#### create Cash dataframe\n",
    "ind = (df_new.Account_Num >1000) & (df_new.Account_Num <1099)\n",
    "df_cash = df_new[ind].groupby(['location','monthdt'])['value'].sum()#.reset_index()\n",
    "tot_cash_by_date = df_cash.reset_index().groupby('monthdt')['value'].sum().reset_index()\n",
    "\n",
    "#### create 4-wall EBITDA per car dataframe\n",
    "# st.write(ext_cars_by_loc)\n",
    "# st.write(df_4webitda)\n",
    "extcarsloc = ext_cars_by_loc.copy()\n",
    "extcarsloc.rename(columns={'Date': 'monthdt'}, inplace=True)\n",
    "ext_cars_loc = extcarsloc.set_index(['location','monthdt'])['value']\n",
    "df_ebitda_by_car = df_4webitda / ext_cars_loc\n",
    "# st.write(df_ebitda_by_car)\n",
    "tot_ebitdacar_by_date = df_ebitda_by_car.reset_index().groupby('monthdt')['value'].sum().reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "c1, c2 = st.columns(2)\n",
    "with c1:\n",
    "    # st.header(\"Overall Revenue Trendline\")\n",
    "    fig = px.bar(df_rev.reset_index(), x='monthdt', y='value', color='location', title=\"Revenue by Location\")\n",
    "    fig.add_scatter(x=tot_rev_by_date['monthdt'], y=tot_rev_by_date['value'], mode='lines+markers', name='Total')\n",
    "    st.plotly_chart(fig)\n",
    "\n",
    "    # st.header(\"Gross Profit Trendline\")\n",
    "    fig3 = px.bar(df_gross.reset_index(), x='monthdt', y='value', color='location', title=\"Gross Profit by Location\")\n",
    "    fig3.add_scatter(x=tot_gross_by_date['monthdt'], y=tot_gross_by_date['value'], mode='lines+markers', name='Total')\n",
    "    st.plotly_chart(fig3)\n",
    "\n",
    "    # st.header(\"Cash Trendline\")\n",
    "    fig5 = px.bar(df_cash.reset_index(), x='monthdt', y='value', color='location', title=\"Gross Profit by Location\")\n",
    "    fig5.add_scatter(x=tot_cash_by_date['monthdt'], y=tot_cash_by_date['value'], mode='lines+markers', name='Total')\n",
    "    st.plotly_chart(fig5)\n",
    "\n",
    "with c2:\n",
    "    # Upper-right column (UR): Cars Serviced by Location\n",
    "    # st.header(\"Cars Serviced by Location\")\n",
    "    fig2 = px.bar(ext_cars_by_loc, x='Date', y='value', color='location', title=\"Cars Serviced by Location\")\n",
    "    fig2.add_scatter(x=tot_cars_by_date['Date'], y=tot_cars_by_date['value'], mode='lines+markers', name='Total')\n",
    "    st.plotly_chart(fig2)\n",
    "\n",
    "    # st.header(\"4-Wall EBITDA Trendline\")\n",
    "    fig4 = px.bar(df_4webitda.reset_index(), x='monthdt', y='value', color='location', title=\"4-Wall EBITDA by Location\")\n",
    "    fig4.add_scatter(x=tot_ebitda_by_date['monthdt'], y=tot_ebitda_by_date['value'], mode='lines+markers', name='Total')\n",
    "    st.plotly_chart(fig4)\n",
    "\n",
    "    # st.header(\"4-Wall EBITDA per car Trendline\")\n",
    "    fig6 = px.bar(df_ebitda_by_car.reset_index(), x='monthdt', y='value', color='location', title=\"4-Wall EBITDA by Car by Location\")\n",
    "    fig6.add_scatter(x=tot_ebitdacar_by_date['monthdt'], y=tot_ebitdacar_by_date['value'], mode='lines+markers', name='Total')\n",
    "    st.plotly_chart(fig6)\n",
    "\n",
    "\n",
    "\n",
    "############################## Trend line test (linear)\n",
    "# Prepare data for forecasting\n",
    "df_grouped = ext_cars_by_loc.groupby('Date').sum().reset_index()\n",
    "# Forecast for the next 3 months\n",
    "future_dates = pd.date_range(start=df_grouped['Date'].max() + pd.DateOffset(months=1), periods=3, freq='M')\n",
    "# Linear Regression Model for forecasting\n",
    "X = np.arange(len(df_grouped)).reshape(-1, 1)\n",
    "y = df_grouped['value']\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "# Predict the next 3 months\n",
    "X_future = np.arange(len(df_grouped), len(df_grouped) + 3).reshape(-1, 1)\n",
    "y_future = model.predict(X_future)\n",
    "# Create a DataFrame for forecasted values\n",
    "forecast_df = pd.DataFrame({\n",
    "    'Date': future_dates,\n",
    "    'value': y_future\n",
    "})\n",
    "# Combine the original and forecasted DataFrames\n",
    "combined_df = pd.concat([df_grouped, forecast_df])\n",
    "# Plotting\n",
    "fig2 = px.bar(ext_cars_by_loc, x='Date', y='value', color='location', title=\"Cars Serviced by Location (w/linear regression trendline)\")\n",
    "# Adding the forecasted values as a line\n",
    "fig2.add_scatter(x=combined_df['Date'], y=combined_df['value'], mode='lines', name='Trend Line')\n",
    "st.plotly_chart(fig2)\n",
    "######################################################\n",
    "\n",
    "\n",
    "####### Create BOXES Showing comparison for previous month and vs. budget for ARO, CPD, LHPC,.... \n",
    "\n",
    "row0 = st.columns(6)\n",
    "row1 = st.columns(6)\n",
    "row2 = st.columns(6)\n",
    "row3 = st.columns(6)\n",
    "row4 = st.columns(6)\n",
    "row5 = st.columns(6)\n",
    "row6 = st.columns(6)\n",
    "row7 = st.columns(6)\n",
    "\n",
    "# ARO\tCPD  \tLHPC\tP-Mix %\t  Big 5 %\tBay Times\n",
    "ind = [( 2, 'ARO'),( 1, 'CPD'),(51, 'LHPC'),(61, 'P-Mix %'),(62, 'Big 5 %'),(63, 'Bay Times')]\n",
    "\n",
    "last2mos = pivot_df.iloc[:,-5:-3].loc[ind,:]\n",
    "last2mos['diffs'] = last2mos.iloc[:,1].sub(last2mos.iloc[:,0], axis = 0) \n",
    "last2mos['diffperc'] = last2mos['diffs'] / last2mos.iloc[:,0]\n",
    "last2mos = last2mos.reset_index().drop(columns=['Account_Num', 'Account'])\n",
    "last2mos.index = pd.RangeIndex(start=0, stop=len(last2mos), step=1)\n",
    "\n",
    "formatting = [\n",
    "    (0, dollar_format),\n",
    "    (1, dollar_format),\n",
    "    (2, format_two_decimals),\n",
    "    (3, perc_format),\n",
    "    (4, perc_format),\n",
    "    (5, format_two_decimals),\n",
    "]\n",
    "\n",
    "for index, func in formatting:\n",
    "    last2mos.iloc[index, 1] = func(last2mos.iloc[index, 1])\n",
    "    # last2mos.loc[index, 'values'] = last2mos[index][2]\n",
    "\n",
    "st.write(last2mos)\n",
    "cnt = 0\n",
    "for col in row0:\n",
    "    tile = col.container()#height=60)\n",
    "    tile.write(ind[cnt][1])\n",
    "    cnt += 1\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for col in row1:\n",
    "    tile = col.container(height=200)\n",
    "    tile.write(last2mos.iloc[cnt,1])\n",
    "    tile.write(\"All\")\n",
    "    tile.write(arrow_format(last2mos.iloc[cnt]['diffperc']))\n",
    "    tile.write('(placeholder budget)')\n",
    "    cnt += 1\n",
    "\n",
    "ind = (df['monthdt'] >= enddate - pd.DateOffset(months=1)) & (df['monthdt'] <= enddate)\n",
    "df2months = df[ind]\n",
    "\n",
    "st.write('here is the df2months df:', df2months)\n",
    "\n",
    "df_loc = df_new[ind].groupby(['location','monthdt'])['value'].mean()#.reset_index()\n",
    "st.write(df_loc)\n",
    "    # + row2 + row3 + row4+ row5 + row6 + row7:\n",
    "    # tile = col.container(height=60)\n",
    "    # tile.title(\":balloon:\")\n",
    "\n",
    "\n",
    "st.write(\"df revenue:\", df_rev)\n",
    "st.write(\"cars by loc:\", ext_cars_by_loc)\n",
    "st.write(\"ARO: \", df_rev / ext_cars_by_loc)\n",
    "st.write(\"df revenue:\", df_rev)\n",
    "\n",
    "\n",
    "\n",
    "# ind_sum = [(11, 'Revenue'),    (12, 'Gross Profit'), (25, '4-Wall EBITDA'), \n",
    "#             (26, '4-Wall FCF'), (27, 'Net Profit'),   (71, '# of Cars Serviced')    ]\n",
    "# ind_avg = [( 1, 'CPD'),            ( 2, 'ARO'),              (21, 'Labor %'),\n",
    "#             (22, 'Controllable %'),(23, 'Uncontrollable %'), (31, 'Cash'),\n",
    "#             (41, 'Gross Profit %'),(42, '4-Wall EBITDA %'),  (43, '4-Wall FCF %'),\n",
    "#             (44, 'Net Profit %'),  (51, 'LHPC'),             (52, 'Revenue Per Employee Hours Worked'),\n",
    "#             (61, 'P-Mix %'),       (62, 'Big 5 %'),          (63, 'Bay Times'),\n",
    "#             (64, 'Discount %'),    (72, 'Gross Profit Per Car'), (73, '4-Wall EBITDA Per Car')]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kordis_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
